{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6020,"status":"ok","timestamp":1727379656030,"user":{"displayName":"Chad Nygard","userId":"11574618599113505803"},"user_tz":420},"id":"hknSoMh4ngz4","outputId":"62b4530b-0e58-4a34-d387-39652ca5cdf9"},"outputs":[],"source":["!pip install pandas scikit-learn numpy altair"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2828,"status":"ok","timestamp":1727380149610,"user":{"displayName":"Chad Nygard","userId":"11574618599113505803"},"user_tz":420},"id":"8YgmHKdNrZlY"},"outputs":[],"source":["import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.metrics import cohen_kappa_score, make_scorer\n","import numpy as np\n","import altair as alt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1291,"status":"ok","timestamp":1727380152483,"user":{"displayName":"Chad Nygard","userId":"11574618599113505803"},"user_tz":420},"id":"SY3tCCG7rd_l","outputId":"51294a34-80f4-4247-825b-2b140c3df619"},"outputs":[],"source":["# Mount Google Drive (execute this cell first)\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":217,"status":"ok","timestamp":1727380155809,"user":{"displayName":"Chad Nygard","userId":"11574618599113505803"},"user_tz":420},"id":"f9DWrwpBrjo0"},"outputs":[],"source":["# Data Loading (Colab) - Adjust the file paths if needed\n","train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n","test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n","sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":222,"status":"ok","timestamp":1727380158466,"user":{"displayName":"Chad Nygard","userId":"11574618599113505803"},"user_tz":420},"id":"CukoAZ6GrpG_"},"outputs":[],"source":["# Install pyarrow if not already installed\n","try:\n","    import pyarrow.parquet as pq\n","except ImportError:\n","    !pip install pyarrow\n","    import pyarrow.parquet as pq"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zsqwBMk8rspA"},"outputs":[],"source":["import pyarrow.parquet as pq\n","import pandas as pd\n","\n","# 1. Efficient Loading with iter_row_groups\n","\n","# Training Data\n","for i in range(pq.read_table('/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet').num_row_groups):\n","    train_chunk = pq.read_table('/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet').read_row_group(i).to_pandas()\n","    # Now, 'train_chunk' is a Pandas DataFrame containing a portion of the training data.\n","    # Process this chunk as needed (e.g., feature engineering, modeling, etc.).\n","    # ... your processing code here ...\n","\n","# Test Data\n","for i in range(pq.read_table('/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet').num_row_groups):\n","    test_chunk = pq.read_table('/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet').read_row_group(i).to_pandas()\n","    # Similarly, 'test_chunk' is a Pandas DataFrame with a portion of the test data.\n","    # Process this chunk as needed.\n","    # ... your processing code here ..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JetggHxIrwqo"},"outputs":[],"source":["# Data Preprocessing\n","\n","# Drop 'PCIAT' columns from train_df\n","pciat_columns = [col for col in train_df.columns if col.startswith('PCIAT')]\n","train_df.drop(pciat_columns, axis=1, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UZ-ikNjMrzoB"},"outputs":[],"source":["# Handle Missing Values\n","# Impute numerical columns with medians and categorical columns with modes for train_df\n","for column in train_df.columns:\n","    if train_df[column].dtype == 'float64' or train_df[column].dtype == 'int64':  # Numerical columns\n","        train_df[column].fillna(train_df[column].median(), inplace=True)\n","    else:  # Categorical columns\n","        train_df[column].fillna(train_df[column].mode()[0], inplace=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ZGdH7gAr1vg"},"outputs":[],"source":["# Impute numerical columns in test_df using medians from train_df\n","for column in test_df.columns:\n","    if test_df[column].dtype == 'float64' or test_df[column].dtype == 'int64':\n","        test_df[column].fillna(train_df[column].median(), inplace=True)\n","    else:\n","        test_df[column].fillna(train_df[column].mode()[0], inplace=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gCG6Mshgr411"},"outputs":[],"source":["# Encode Categorical Variables\n","# Get categorical columns from data dictionary\n","categorical_columns = data_dictionary_df[data_dictionary_df['Type'] == 'categorical int']['Field'].tolist()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_7h3e9_Xr7uQ"},"outputs":[],"source":["# Exclude 'id' from categorical columns\n","categorical_columns = [col for col in categorical_columns if col in train_df.columns and col != 'id']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M5d1SXXTr8ms"},"outputs":[],"source":["# Apply one-hot encoding\n","encoder = OneHotEncoder(handle_unknown='ignore')\n","encoded_train = pd.DataFrame(encoder.fit_transform(train_df[categorical_columns]).toarray())\n","encoded_test = pd.DataFrame(encoder.transform(test_df[categorical_columns]).toarray())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9kGg_aVFr_eJ"},"outputs":[],"source":["# Rename encoded columns\n","encoded_train.columns = encoder.get_feature_names_out(categorical_columns)\n","encoded_test.columns = encoder.get_feature_names_out(categorical_columns)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yis8rk2ZsAMG"},"outputs":[],"source":["# Concatenate encoded features with original DataFrames\n","train_df = pd.concat([train_df.drop(categorical_columns, axis=1), encoded_train], axis=1)\n","test_df = pd.concat([test_df.drop(categorical_columns, axis=1), encoded_test], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LRWzq3desFyp"},"outputs":[],"source":["# 3. Refine Actigraphy Feature Engineering\n","# Revisit total_duration_hours calculation (adjust based on actual data meaning)\n","def extract_features(df):\n","    # ... (other feature calculations)\n","\n","    # Assuming 'step' represents 5-second intervals and we want total duration in hours\n","    features['total_duration_hours'] = (\n","        df.groupby('id')['step'].max() * 5 / 3600\n","    )\n","\n","    # ... (rest of the function)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PivNP24MsGS9"},"outputs":[],"source":["# Add more features (example: mean and std of X, Y, Z)\n","def extract_features(df):\n","    # ... (other feature calculations)\n","\n","    features['mean_X'] = df.groupby('id')['X'].mean()\n","    features['std_X'] = df.groupby('id')['X'].std()\n","    features['mean_Y'] = df.groupby('id')['Y'].mean()\n","    features['std_Y'] = df.groupby('id')['Y'].std()\n","    features['mean_Z'] = df.groupby('id')['Z'].mean()\n","    features['std_Z'] = df.groupby('id')['Z'].std()\n","\n","    # ... (rest of the function)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f5rwx-Lwy-kP"},"outputs":[],"source":["print(actigraphy_train_df.columns)\n","print(actigraphy_test_df.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ikoW1baMz-RI"},"outputs":[],"source":["# Check if the column exists (case-sensitive)\n","if 'non_wear_flag' in actigraphy_train_df.columns:\n","    actigraphy_train_df = actigraphy_train_df[actigraphy_train_df['non_wear_flag'] == 1]\n","else:\n","    print(\"Warning: 'non_wear_flag' column not found in actigraphy_train_df. Skipping filtering.\")\n","\n","if 'non_wear_flag' in actigraphy_test_df.columns:\n","    actigraphy_test_df = actigraphy_test_df[actigraphy_test_df['non_wear_flag'] == 1]\n","else:\n","    print(\"Warning: 'non_wear_flag' column not found in actigraphy_test_df. Skipping filtering.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ysulmCcl1rT9"},"outputs":[],"source":["# Check if the column exists before accessing it\n","if 'non_wear_flag' in actigraphy_train_df.columns:\n","    # Check for missing values in 'non_wear_flag'\n","    if actigraphy_train_df['non_wear_flag'].isnull().any():\n","        # Decide how to handle missing values (e.g., drop rows, impute)\n","        # Example: Drop rows with missing values\n","        actigraphy_train_df.dropna(subset=['non_wear_flag'], inplace=True)\n","\n","    # Filter out non-wear periods\n","    actigraphy_train_df = actigraphy_train_df[actigraphy_train_df['non_wear_flag'] == 1]\n","else:\n","    print(\"Warning: 'non_wear_flag' column not found in actigraphy_train_df. Skipping filtering.\")\n","\n","# ... (similar check for actigraphy_test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QsvNxMCT1nrE"},"outputs":[],"source":["# Check if the column exists before accessing it\n","if 'non_wear_flag' in actigraphy_train_df.columns:\n","    # Check for missing values in 'non_wear_flag'\n","    if actigraphy_train_df['non_wear_flag'].isnull().any():\n","        # Decide how to handle missing values (e.g., drop rows, impute)\n","        # Example: Drop rows with missing values\n","        actigraphy_train_df.dropna(subset=['non_wear_flag'], inplace=True)\n","\n","    # Filter out non-wear periods\n","    actigraphy_train_df = actigraphy_train_df[actigraphy_train_df['non_wear_flag'] == 1]\n","else:\n","    print(\"Warning: 'non_wear_flag' column not found in actigraphy_train_df. Skipping filtering.\")\n","\n","# ... (similar check for actigraphy_test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1FxoB5bj1ig5"},"outputs":[],"source":["# Check if the column exists before accessing it\n","if 'non_wear_flag' in actigraphy_train_df.columns:\n","    # Check for missing values in 'non_wear_flag'\n","    if actigraphy_train_df['non_wear_flag'].isnull().any():\n","        # Decide how to handle missing values (e.g., drop rows, impute)\n","        # Example: Drop rows with missing values\n","        actigraphy_train_df.dropna(subset=['non_wear_flag'], inplace=True)\n","\n","    # Filter out non-wear periods\n","    actigraphy_train_df = actigraphy_train_df[actigraphy_train_df['non_wear_flag'] == 1]\n","else:\n","    print(\"Warning: 'non_wear_flag' column not found in actigraphy_train_df. Skipping filtering.\")\n","\n","# ... (similar check for actigraphy_test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UJ4sObhUzTZf"},"outputs":[],"source":["# Check if the column exists before accessing it\n","if 'non_wear_flag' in actigraphy_train_df.columns:\n","    actigraphy_train_df = actigraphy_train_df[actigraphy_train_df['non_wear_flag'] == 0]\n","else:\n","    print(\"Warning: 'non_wear_flag' column not found in actigraphy_train_df. Skipping filtering.\")\n","\n","if 'non_wear_flag' in actigraphy_test_df.columns:\n","    actigraphy_test_df = actigraphy_test_df[actigraphy_test_df['non_wear_flag'] == 0]\n","else:\n","    print(\"Warning: 'non_wear_flag' column not found in actigraphy_test_df. Skipping filtering.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UNB5PPFFsK70"},"outputs":[],"source":["# Feature Engineering (from actigraphy data)\n","# Preprocess Actigraphy Data\n","actigraphy_train_df = actigraphy_train_df[actigraphy_train_df['non_wear_flag'] == 0]\n","actigraphy_test_df = actigraphy_test_df[actigraphy_test_df['non_wear_flag'] == 0]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5jVdGS_usNKj"},"outputs":[],"source":["# Feature Extraction\n","actigraphy_train_features = extract_features(actigraphy_train_df)\n","actigraphy_test_features = extract_features(actigraphy_test_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DmQq_yVQsPqC"},"outputs":[],"source":["# Merge with Tabular Data\n","train_df = train_df.merge(actigraphy_train_features, on='id', how='left')\n","test_df = test_df.merge(actigraphy_test_features, on='id', how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UB1DRs3ssRDU"},"outputs":[],"source":["# 4. Merge and Check for NaN Values\n","# ... (merge actigraphy features)\n","\n","# Check for NaN values after merging\n","print(\"\\nMissing Values in Train Data after merging:\")\n","print((train_df.isnull().sum() / len(train_df) * 100).to_markdown(numalign=\"left\", stralign=\"left\"))\n","\n","print(\"\\nMissing Values in Test Data after merging:\")\n","print((test_df.isnull().sum() / len(test_df) * 100).to_markdown(numalign=\"left\", stralign=\"left\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XvEiyg0SsUrw"},"outputs":[],"source":["# Impute or remove NaN values (choose appropriate strategy)\n","# Example: Impute with median for numerical columns\n","for col in train_df.select_dtypes(include=[np.number]).columns:\n","    train_df[col].fillna(train_df[col].median(), inplace=True)\n","    test_df[col].fillna(train_df[col].median(), inplace=True)  # Use train_df median for test_df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JxeDDuv4sbeP"},"outputs":[],"source":["# 1. Analyze Numerical Feature Distributions\n","from scipy.stats import skew, kurtosis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6AKm7CQnsdKY"},"outputs":[],"source":["# Calculate skewness and kurtosis for numerical columns\n","numerical_columns = train_df.select_dtypes(include=[np.number]).columns.tolist()\n","skewness = train_df[numerical_columns].skew()\n","kurtosis = train_df[numerical_columns].kurtosis()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s-cGYY4sserb"},"outputs":[],"source":["# Identify columns with high skewness or kurtosis (you can adjust the thresholds)\n","high_skew_columns = skewness[abs(skewness) > 1].index.tolist()\n","high_kurtosis_columns = kurtosis[abs(kurtosis) > 3].index.tolist()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EjAcjcOmsicd"},"outputs":[],"source":["# Display summary statistics for these columns\n","print(\"Summary statistics for numerical features with high skewness or kurtosis:\")\n","print(train_df[high_skew_columns + high_kurtosis_columns].describe().to_markdown(numalign=\"left\", stralign=\"left\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2uTQZz-ysmmF"},"outputs":[],"source":["# Visualize distributions of features with high skewness or kurtosis\n","for col in high_skew_columns + high_kurtosis_columns:\n","    chart = alt.Chart(train_df).mark_bar().encode(\n","        x=alt.X(col + ':Q', bin=True),\n","        y='count()',\n","        tooltip=[col, 'count()']\n","    ).properties(\n","        title=f'Distribution of {col}'\n","    )\n","    chart.save(f'distribution_{col}.json')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvGEKv0psozd"},"outputs":[],"source":["# 2. Assess Categorical Feature Cardinality\n","# Count unique categories for categorical columns\n","categorical_columns = train_df.select_dtypes(include=['object']).columns.tolist()\n","cardinality = train_df[categorical_columns].nunique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vI3XTtTtsqgA"},"outputs":[],"source":["# Identify high-cardinality columns (adjust the threshold if needed)\n","high_cardinality_columns"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN6mGb8FByBiQmSRMyKbad+","gpuType":"T4","provenance":[{"file_id":"160UrzR9Tsju4zzbIUZvkWlk8XiMaLB5D","timestamp":1727377152959},{"file_id":"1sCpik7DSrczFTBXngvekASrILGhjyN-Q","timestamp":1727377111442}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
